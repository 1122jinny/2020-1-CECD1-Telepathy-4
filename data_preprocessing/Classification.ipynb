{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "import tensorflow as tf # 1.15.0 버전 사용\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\oym91\\OneDrive\\Desktop\\graph_all\\\\\"\n",
    "trainFileList = os.listdir(path+'train')\n",
    "testFileList = os.listdir(path+'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainFileList = [x for x in trainFileList if 'png' in x]\n",
    "testFileList = [x for x in testFileList if 'png' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = {'balance' : 0, 'decrease' : 1, 'increase' : 2, 'shortcycle' : 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array에 각 데이터를 넣어주는 작업\n",
    "for i, file in enumerate(trainFileList):\n",
    "    #label, nm, tr, _ = file.split('_') # 예시 aa_bc_01_02.jpg\n",
    "    label, _ = file.split('_')\n",
    "    code, ext = _.split('.') # 예시 02.jpg\n",
    "\n",
    "    # 이미지 불러오기\n",
    "    new_img = load_img(path+'train\\\\'+file)\n",
    "    # 이미지를 array 형식으로 변형\n",
    "    arr_img = img_to_array(new_img)\n",
    "    # (1, 28, 28, 3) 검정색 글씨뿐이지만 나름 RGB...zz\n",
    "    img = arr_img.reshape((1,)+arr_img.shape)\n",
    "\n",
    "    # 첫 번째 데이터의 경우 container를 생성\n",
    "    if i == 0 :  # train 데이터\n",
    "        container = img\n",
    "        labels = word[label]\n",
    "    # 첫 번쨰가 아닌경우 array에 계속 쌓아나감\n",
    "    else:\n",
    "        container = np.vstack([container, img])\n",
    "        labels = np.vstack([labels, word[label]])\n",
    "\n",
    "xTrain = container\n",
    "# 카테고리 데이터 one-hot encoding\n",
    "yTrain = np_utils.to_categorical(labels,5)\n",
    "\n",
    "# 위의 작업을 동일하게 test데이터에도 진행\n",
    "for i, file in enumerate(testFileList):\n",
    "    # label, nm, tr, _ = file.split('_')\n",
    "    label, _ = file.split('_')\n",
    "    code, ext = _.split('.')\n",
    "\n",
    "    new_img = load_img(path+'test\\\\'+file)\n",
    "    arr_img = img_to_array(new_img)\n",
    "    img = arr_img.reshape((1,)+arr_img.shape)\n",
    "    if i == 0 :  # test 데이터\n",
    "        container = img\n",
    "        labels = word[label]\n",
    "    else:\n",
    "        container = np.vstack([container, img])\n",
    "        labels = np.vstack([labels, word[label]])\n",
    "\n",
    "xTest = container\n",
    "yTest = np_utils.to_categorical(labels,5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 288, 864, 3) (79, 1)\n",
      "(79, 288, 864, 3) (79, 5)\n",
      "(79, 288, 864, 3) (79, 5)\n"
     ]
    }
   ],
   "source": [
    "print(container.shape, labels.shape)\n",
    "print(xTrain.shape, yTrain.shape)\n",
    "print(xTest.shape, yTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrain.astype('float32')/255\n",
    "xTest = xTest.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구성\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3,3), padding='same', input_shape=(288,864,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3,3),padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 129s 16s/step - loss: 43.0097 - accuracy: 0.3038\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 120s 15s/step - loss: 1.5294 - accuracy: 0.3038\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 82s 10s/step - loss: 1.5066 - accuracy: 0.1899\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 69s 9s/step - loss: 1.4740 - accuracy: 0.2785\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 80s 10s/step - loss: 1.5002 - accuracy: 0.2532\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 83s 10s/step - loss: 1.4874 - accuracy: 0.2785\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 76s 10s/step - loss: 1.7092 - accuracy: 0.2658\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 79s 10s/step - loss: 1.4343 - accuracy: 0.2532\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 84s 10s/step - loss: 1.4225 - accuracy: 0.2785\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 82s 10s/step - loss: 1.4800 - accuracy: 0.1772\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 78s 10s/step - loss: 1.4338 - accuracy: 0.2405\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 81s 10s/step - loss: 1.5461 - accuracy: 0.2658\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 78s 10s/step - loss: 1.4708 - accuracy: 0.2405\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 83s 10s/step - loss: 1.5206 - accuracy: 0.2785\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 90s 11s/step - loss: 1.4159 - accuracy: 0.2152\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 816s 102s/step - loss: 1.3962 - accuracy: 0.3038\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 81s 10s/step - loss: 1.4182 - accuracy: 0.2405\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 78s 10s/step - loss: 1.4556 - accuracy: 0.3291\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 90s 11s/step - loss: 1.4343 - accuracy: 0.2152\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 94s 12s/step - loss: 1.4106 - accuracy: 0.2152\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 91s 11s/step - loss: 1.4075 - accuracy: 0.3038\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 100s 12s/step - loss: 1.4134 - accuracy: 0.1899\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 94s 12s/step - loss: 1.3886 - accuracy: 0.2785\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 98s 12s/step - loss: 1.4119 - accuracy: 0.3165\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 86s 11s/step - loss: 1.4048 - accuracy: 0.2911\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 95s 12s/step - loss: 1.4020 - accuracy: 0.2532\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 94s 12s/step - loss: 1.4057 - accuracy: 0.2532\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 88s 11s/step - loss: 1.4045 - accuracy: 0.2278\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 87s 11s/step - loss: 1.3857 - accuracy: 0.2911\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 97s 12s/step - loss: 1.4109 - accuracy: 0.2532\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 95s 12s/step - loss: 1.4062 - accuracy: 0.2532\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 93s 12s/step - loss: 1.3824 - accuracy: 0.3418\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 97s 12s/step - loss: 1.3927 - accuracy: 0.2911\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 98s 12s/step - loss: 1.3911 - accuracy: 0.3291\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 103s 13s/step - loss: 1.3898 - accuracy: 0.2658\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 106s 13s/step - loss: 1.3819 - accuracy: 0.3165\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 95s 12s/step - loss: 1.3627 - accuracy: 0.3038\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 102s 13s/step - loss: 1.3671 - accuracy: 0.3418\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 94s 12s/step - loss: 1.3468 - accuracy: 0.3671\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 97s 12s/step - loss: 1.2564 - accuracy: 0.4430\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 100s 12s/step - loss: 1.0831 - accuracy: 0.5190\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 93s 12s/step - loss: 0.7587 - accuracy: 0.7468\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 107s 13s/step - loss: 0.4484 - accuracy: 0.8608\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 96s 12s/step - loss: 0.2222 - accuracy: 0.9367\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 98s 12s/step - loss: 0.0841 - accuracy: 0.9747\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 96s 12s/step - loss: 0.0782 - accuracy: 0.9747\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 88s 11s/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 91s 11s/step - loss: 0.0358 - accuracy: 0.9873\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 95s 12s/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 92s 12s/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 100s 13s/step - loss: 0.0184 - accuracy: 0.9873\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 103s 13s/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 107s 13s/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 96s 12s/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 100s 12s/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 110s 14s/step - loss: 7.9272e-04 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 97s 12s/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 99s 12s/step - loss: 9.8348e-04 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "2/8 [======>.......................] - ETA: 46s - loss: 0.0011 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "history = model.fit(xTrain, yTrain, batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict_classes(xTest)\n",
    "\n",
    "answer = []\n",
    "for i in yTest:\n",
    "    answer.append(np.argmax(i))\n",
    "\n",
    "yTest_label = []\n",
    "for y in yTest:\n",
    "    yTest_label.append(np.argmax(y))\n",
    "\n",
    "accuracy_score(yTest_label, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
